<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>淘天ai agent面经 | Life is not a race, but a journey</title><meta name="author" content="Xiang Li"><meta name="copyright" content="Xiang Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Collected interview experiences for the TaoTian AI agent.">
<meta property="og:type" content="article">
<meta property="og:title" content="淘天ai agent面经">
<meta property="og:url" content="https://xloverflow.github.io/2025/12/14/Personal/%E6%B7%98%E5%A4%A9ai-agent%E9%9D%A2%E7%BB%8F/index.html">
<meta property="og:site_name" content="Life is not a race, but a journey">
<meta property="og:description" content="Collected interview experiences for the TaoTian AI agent.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg">
<meta property="article:published_time" content="2025-12-14T03:28:44.000Z">
<meta property="article:modified_time" content="2026-02-15T05:04:17.013Z">
<meta property="article:author" content="Xiang Li">
<meta property="article:tag" content="AI Agent">
<meta property="article:tag" content="面经">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "淘天ai agent面经",
  "url": "https://xloverflow.github.io/2025/12/14/Personal/%E6%B7%98%E5%A4%A9ai-agent%E9%9D%A2%E7%BB%8F/",
  "image": "https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg",
  "datePublished": "2025-12-14T03:28:44.000Z",
  "dateModified": "2026-02-15T05:04:17.013Z",
  "author": [
    {
      "@type": "Person",
      "name": "Xiang Li",
      "url": "https://xloverflow.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xloverflow.github.io/2025/12/14/Personal/%E6%B7%98%E5%A4%A9ai-agent%E9%9D%A2%E7%BB%8F/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '淘天ai agent面经',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://pica.zhimg.com/80/v2-b6830c2136b7784c0aba649af7ec2867_1440w.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/List/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/List/gallery/"><i class="fa-fw fa fa-image"></i><span> Album</span></a></li><li><a class="site-page child" href="/List/movies/"><i class="fa-fw fas fa-video"></i><span> Videos</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Life is not a race, but a journey</span></a><a class="nav-page-title" href="/"><span class="site-name">淘天ai agent面经</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/List/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/List/gallery/"><i class="fa-fw fa fa-image"></i><span> Album</span></a></li><li><a class="site-page child" href="/List/movies/"><i class="fa-fw fas fa-video"></i><span> Videos</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><!-- Language switch button styled like menu item--><div class="menus_items lang-switch"><div class="menus_item"><a class="site-page lang-toggle" href="/zh/"><i class="fas fa-language fa-fw"></i><span> 中文</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">淘天ai agent面经</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-14T03:28:44.000Z" title="Created 2025-12-13 22:28:44">2025-12-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-15T05:04:17.013Z" title="Updated 2026-02-15 00:04:17">2026-02-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Interview-Experience/">Interview Experience</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="taotian-ai-agent-interview-experience">TaoTian AI Agent
Interview Experience</h1>
<h2
id="introduction-to-the-rag-process-understanding-encoding-models-principles-advantages-and-disadvantages-how-to-evaluate-encoding-model-capabilities">1.
Introduction to the RAG Process; Understanding Encoding Models,
Principles, Advantages, and Disadvantages; How to Evaluate Encoding
Model Capabilities</h2>
<p>The core process of RAG (Retrieval-Augmented Generation) consists of:
<strong>Data Preparation</strong> (cleaning, chunking, vectorization,
storage), <strong>Retrieval</strong> (similarity search),
<strong>Augmentation</strong> (injecting context into the prompt), and
<strong>Generation</strong> (LLM output).</p>
<h3
id="principles-and-advantagesdisadvantages-of-encoding-models">Principles
and Advantages/Disadvantages of Encoding Models</h3>
<p>Encoding models are typically based on <strong>BERT/RoBERTa</strong>
and other encoder-only architectures. They map text into
high-dimensional vector space using a bidirectional attention
mechanism.</p>
<ul>
<li><strong>Principle</strong>: Utilizing contrastive learning to ensure
semantically similar texts are closer together in vector space (Cosine
Similarity).</li>
<li><strong>Advantages</strong>: High computational efficiency, suitable
for large-scale semantic searches.</li>
<li><strong>Disadvantages</strong>: Limited by context window length
(usually 512-812 characters); unable to understand extremely complex
long-range logic.</li>
</ul>
<h3 id="evaluation-metrics">Evaluation Metrics</h3>
<ul>
<li><strong>MTEB (Massive Text Embedding Benchmark)</strong>: Currently
recognized as an authoritative leaderboard.</li>
<li><strong>Retrieval Accuracy</strong>: <span class="math inline">\(Hit
Rate@K\)</span> (whether the top K results contain the correct answer)
and <strong>MRR</strong> (Mean Reciprocal Rank).</li>
</ul>
<h2
id="what-are-the-classifications-of-rag-what-implementation-frameworks-exist-for-multimodal-rag-how-are-pseudo-multimodal-rag-and-multimodal-rag-implemented-and-what-are-the-differences-what-type-of-multimodal-rag-can-clip-be-used-for-and-why">2.
What are the Classifications of RAG; What Implementation Frameworks
Exist for Multimodal RAG; How are Pseudo-Multimodal RAG and Multimodal
RAG Implemented, and What are the Differences; What Type of Multimodal
RAG Can CLIP Be Used For, and Why</h2>
<h3 id="naive-rag-simple-retrieval">Naive RAG (Simple Retrieval)</h3>
<p>This is the most basic <strong>Index -&gt; Retrieve -&gt; Augment
-&gt; Generation</strong> linear process.</p>
<ul>
<li><strong>Method</strong>: Chunk documents and store them in a vector
database. When a user asks a question, convert the question into a
vector to find the most similar Top-K segments, which are then fed to
the LLM.</li>
<li><strong>Drawbacks</strong>:
<ul>
<li><strong>Slow/Low Accuracy Retrieval</strong>: Vector matching may
only find segments that are keyword-similar but semantically
unrelated.</li>
<li><strong>Context Break</strong>: Chunking may cut off an important
sentence, leading to incomplete information.</li>
</ul></li>
</ul>
<h3 id="advanced-rag-preprocessing-postprocessing">Advanced RAG
(Preprocessing + Postprocessing)</h3>
<p>To address the pain points of simple retrieval, a large number of
optimization strategies are added at both ends of the retrieval
process:</p>
<ul>
<li><strong>Preprocessing (Pre-Retrieval)</strong>:
<ul>
<li><strong>Query Rewriting</strong>: If the user’s question is vague,
first let the LLM rewrite the question to be clearer or generate
multiple variants (Multi-Query).</li>
<li><strong>Hypothetical Answer (HyDE)</strong>: First, let the LLM
guess an answer, using this “hypothetical answer” to search, which is
often more accurate than searching directly with the “question.”</li>
</ul></li>
<li><strong>Postprocessing (Post-Retrieval)</strong>:
<ul>
<li><strong>Re-ranking</strong>: After vector search retrieves 100
results, use a more precise model (Cross-Encoder) to select the 5 most
relevant ones.</li>
<li><strong>Context Compression</strong>: Simplify lengthy retrieved
texts to retain only key information, preventing the LLM from “getting
lost in the middle.”</li>
</ul></li>
</ul>
<h3 id="modular-rag-modular-composition">Modular RAG (Modular
Composition)</h3>
<p>This is the current cutting-edge form, which is no longer linear but
<strong>atomic and plugin-based</strong>.</p>
<ul>
<li><strong>Core Logic</strong>: Decomposing RAG into different
functional modules that can be flexibly combined based on task
requirements.</li>
<li><strong>Examples of New Modules</strong>:
<ul>
<li><strong>Search Module</strong>: Not only searches the vector
database but can also search Google or enterprise knowledge graphs.</li>
<li><strong>Memory Module</strong>: Remembers the user’s previous
conversational habits.</li>
<li><strong>Rewrite/Route Module</strong>: Automatically decides whether
to query the database or generate directly based on the question
type.</li>
</ul></li>
<li><strong>Features</strong>: Supports <strong>iteration</strong> and
<strong>loops</strong>. For example, if a search reveals insufficient
information, it will automatically trigger the “re-search” module until
enough information is gathered.</li>
</ul>
<table>
<colgroup>
<col style="width: 19%" />
<col style="width: 17%" />
<col style="width: 30%" />
<col style="width: 32%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Dimension</strong></th>
<th><strong>Naive RAG</strong></th>
<th><strong>Advanced RAG</strong></th>
<th><strong>Modular RAG</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Process</strong></td>
<td>Linear (Straight)</td>
<td>Linear + Pre/Post Enhancements</td>
<td>Modular, Non-linear (e.g., loops, branches)</td>
</tr>
<tr class="even">
<td><strong>Core Technology</strong></td>
<td>Vector Retrieval</td>
<td>Re-ranking, Query Transformation</td>
<td>Intelligent Routing, Multi-source Fusion</td>
</tr>
<tr class="odd">
<td><strong>Pain Points Addressed</strong></td>
<td>Achieved from scratch</td>
<td>Addressed retrieval noise and semantic alignment</td>
<td>Solved complex tasks and long process issues</td>
</tr>
</tbody>
</table>
<h3 id="multimodal-rag-implementation">Multimodal RAG
Implementation</h3>
<ul>
<li><strong>Implementation Frameworks</strong>: LlamaIndex, LangChain
(Multi-modal), Unstructured.io.</li>
<li><strong>Pseudo-Multimodal RAG</strong>: Achieved through
<strong>Captioning</strong>. Converts images/videos into textual
descriptions and stores them in traditional text vector databases.
<ul>
<li><strong>Difference</strong>: Pseudo-multimodal loses visual details;
true multimodal matches directly in a unified vector space (Multimodal
Embedding).</li>
</ul></li>
<li><strong>Role of CLIP</strong>: Serves as the foundation of
<strong>true multimodal RAG</strong>. It achieves representation of
images and text in the same feature space through image-text pairing
training, suitable for “searching images with text” or “searching images
with images.”</li>
</ul>
<h2
id="how-to-evaluate-rag-what-is-the-most-important-aspect-of-the-rag-evaluation-system">3.
How to Evaluate RAG; What is the Most Important Aspect of the RAG
Evaluation System</h2>
<p>The core of the evaluation system is the <strong>RAG
Triad</strong>:</p>
<ol type="1">
<li><strong>Faithfulness</strong>: Does the answer come from the
retrieved context?</li>
<li><strong>Answer Relevance</strong>: Does the answer address the
query?</li>
<li><strong>Context Precision</strong>: Does the retrieved information
contain the correct answer?</li>
</ol>
<h2
id="what-are-the-pain-points-of-traditional-rag-introduce-graphrag-what-are-the-challenges-of-graphrag-how-does-graphrag-handle-incremental-scenarios">4.
What are the Pain Points of Traditional RAG; Introduce GraphRAG, What
are the Challenges of GraphRAG; How Does GraphRAG Handle Incremental
Scenarios</h2>
<h3 id="pain-points-of-traditional-rag">Pain Points of Traditional
RAG</h3>
<ul>
<li><strong>Poor Global Understanding</strong>: Difficult to answer
macro questions like “What is the main idea of this document?”</li>
<li><strong>Weak Long-range Associations</strong>: Unable to connect
implicit entity relationships across documents and paragraphs.</li>
</ul>
<h3 id="graphrag">GraphRAG</h3>
<ul>
<li><strong>Challenges</strong>: The cost of building the graph is
extremely high (LLM extraction of entity relationships is
time-consuming); schema design is complex.</li>
<li><strong>Incremental Scenarios</strong>: Achieved through
<strong>Graph Consolidation</strong>. When new entities enter, use LLM
for entity disambiguation, merging duplicate nodes and updating existing
cluster summaries.</li>
</ul>
<h2
id="introduce-the-responsibilities-of-fine-tuning-what-is-the-most-important-aspect-of-fine-tuning-large-models">5.
Introduce the Responsibilities of Fine-tuning; What is the Most
Important Aspect of Fine-tuning Large Models</h2>
<p><strong>Responsibilities</strong>: Domain knowledge injection, format
alignment (Instruction Following), style transfer.</p>
<p><strong>Most Important Aspect</strong>: <strong>Data
Quality</strong>. As stated in the LIMA paper: <em>Less Is More for
Alignment</em>, 1000 high-quality data points far outweigh 100,000 dirty
data points.</p>
<h2
id="what-are-the-methods-of-post-training-what-are-the-methods-of-fine-tuning-how-are-they-done-lora-principles-and-parameter-count">6.
What are the Methods of Post-training; What are the Methods of
Fine-tuning, How are They Done; LoRA Principles and Parameter Count</h2>
<h3 id="post-training-methods">Post-training Methods</h3>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 11%" />
<col style="width: 25%" />
<col style="width: 26%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Stage / Method</strong></th>
<th><strong>Core Objective</strong></th>
<th><strong>Core Approach</strong></th>
<th><strong>Pros and Cons Analysis</strong></th>
<th><strong>Applicable Scenarios</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>1. Supervised Fine-tuning (SFT)</strong></td>
<td>Teach the model to converse and follow instructions</td>
<td>Supervised training using <span class="math inline">\((Prompt,
Response)\)</span> data pairs.</td>
<td><strong>Pros</strong>: Quick results, foundational for
conversational ability. <strong>Cons</strong>: Difficult to address
value preference issues.</td>
<td>Basic conversational ability building, specific format alignment
(e.g., JSON).</td>
</tr>
<tr class="even">
<td><strong>2. Continuous Pre-training (CPT)</strong></td>
<td>Inject domain knowledge</td>
<td>Train on pure text in specific domains using Next Token
Prediction.</td>
<td><strong>Pros</strong>: Significantly enhances industry knowledge.
<strong>Cons</strong>: Does not change interaction patterns, high
computational cost.</td>
<td>Building expert models in vertical domains like healthcare, law,
finance.</td>
</tr>
<tr class="odd">
<td><strong>3. Reinforcement Learning (RLHF - PPO)</strong></td>
<td>Extreme human preference alignment</td>
<td>Train a reward model (RM) and update the policy using PPO
algorithm.</td>
<td><strong>Pros</strong>: High ceiling, makes the model “smarter” and
safer. <strong>Cons</strong>: Extremely complex process, requires three
models to run simultaneously, training is very unstable.</td>
<td>Final refinement of top closed-source/open-source models (e.g.,
GPT-4, Llama 3).</td>
</tr>
<tr class="even">
<td><strong>4. Direct Preference Optimization (DPO)</strong></td>
<td>Efficient preference alignment</td>
<td>Abandon the reward model, directly calculate loss on (best answer,
worst answer) pairs.</td>
<td><strong>Pros</strong>: Simple, stable, low memory usage, currently
the most mainstream. <strong>Cons</strong>: Sensitive to data
distribution.</td>
<td>Most enterprise-level conversational models and fine-tuning
projects.</td>
</tr>
<tr class="odd">
<td><strong>5. Modular Fine-tuning (LoRA / PEFT)</strong></td>
<td>Low-cost task adaptation</td>
<td>Freeze original parameters and only train low-rank matrices (Rank
Decomposition) in the bypass.</td>
<td><strong>Pros</strong>: Extremely small parameter count (&lt;1%),
very low memory requirements. <strong>Cons</strong>: Performance ceiling
slightly lower than full fine-tuning.</td>
<td>Adaptation for downstream tasks under computational constraints,
multi-task switching.</td>
</tr>
<tr class="even">
<td><strong>6. Hybrid Optimization (ORPO)</strong></td>
<td>One-step alignment</td>
<td>Combine SFT and alignment without needing a reference model.</td>
<td><strong>Pros</strong>: Extremely simple process, high computational
efficiency. <strong>Cons</strong>: Relatively new technology, less
community accumulation.</td>
<td>Lightweight projects pursuing extreme training efficiency.</td>
</tr>
</tbody>
</table>
<h3 id="fine-tuning-methods">Fine-tuning Methods</h3>
<ul>
<li><strong>Full Fine-tuning</strong>: Full parameter fine-tuning, good
results but extremely high computational cost.</li>
<li><strong>PEFT (Parameter-Efficient Fine-tuning)</strong>: Such as
LoRA, P-Tuning, Adapter.</li>
</ul>
<h3 id="lora-principles">LoRA Principles</h3>
<p>Parallel two low-rank matrices <span class="math inline">\(A\)</span>
and <span class="math inline">\(B\)</span> next to the pre-trained
weights. <span class="math display">\[
W_{new} = W_{base} + \Delta W = W_{base} + A \times B
\]</span> <strong>Parameter Count</strong>: Extremely small, usually
less than 1% of the original model. The calculation formula is <span
class="math inline">\(2 \times r \times d_{model}\)</span> (where <span
class="math inline">\(r\)</span> is the rank).</p>
<h2 id="introduce-dpo-what-is-the-difference-between-dpo-and-ppo">7.
Introduce DPO; What is the Difference Between DPO and PPO</h2>
<h3 id="ppo-principles">PPO Principles</h3>
<p><strong>PPO (Reinforcement Learning from Human Feedback)</strong>:
Requires training a <strong>Reward Model</strong>, updating the policy
through policy gradient. The process is complex and training is very
unstable.</p>
<h3 id="why-is-ppo-training-unstable">Why is PPO Training Unstable?</h3>
<ul>
<li><strong>Credit Assignment Problem</strong>: An LLM generates a
sentence containing dozens of tokens, but the reward is usually given as
a total score only at the end. PPO finds it difficult to accurately
determine which word led to a high or low score, and this “sparse
feedback” causes gradient updates to oscillate.</li>
<li><strong>Dual Distribution Drift</strong>: PPO involves two dynamic
systems: one is the <strong>policy model</strong> changing, and the
other is the <strong>value model</strong> chasing. If the value model
estimates inaccurately, the advantage function provided will mislead the
policy model, causing training to collapse instantly.</li>
<li><strong>Non-stationarity and KL Penalty</strong>: To prevent the
model from deviating, PPO must include a KL divergence constraint.
However, this coefficient is very difficult to tune—if set too high, the
model does not learn (does not update), and if set too low, the model
outputs gibberish (Reward Hacking).</li>
</ul>
<h3 id="core-essence-of-dpo-and-orpo">Core Essence of DPO and ORPO</h3>
<p><strong>DPO (Direct Preference Optimization)</strong></p>
<ul>
<li><strong>Core Principle</strong>: Utilizes mathematical techniques to
transform the alignment problem originally requiring “reinforcement
learning” into a <strong>“lookup comparison”</strong> problem.
<strong>No reward model needed</strong>. It directly performs maximum
likelihood estimation on preference data, converting the reinforcement
learning objective into simple binary cross-entropy loss. Simpler, more
stable, and efficient.</li>
<li><strong>Why Stable</strong>: It establishes an analytical solution,
proving that <strong>the optimal policy model is proportional to the
logit probabilities it generates</strong>. During training, as long as
the probability increase for “good answers” is <strong>greater
than</strong> that for “bad answers,” the model evolves. It does not
involve complex sampling and scoring processes; it is essentially
<strong>contrastive learning</strong>.</li>
</ul>
<p><strong>ORPO (Odds Ratio Preference Optimization)</strong></p>
<ul>
<li><strong>Core Principle</strong>: Directly modifies the loss function
of SFT. It believes that the model should not only learn “what to say”
but also “what not to say.”</li>
<li><strong>Core Logic</strong>:
<ol type="1">
<li><strong>Weaken Negative Samples</strong>: It directly penalizes the
probability of generating negative samples (Rejected) using the
<strong>Odds Ratio</strong> statistical measure.</li>
<li><strong>Single-stage Alignment</strong>: It does not require the
four models of PPO, nor does it need the reference model of DPO, relying
solely on one model to simultaneously complete “knowledge learning” and
“preference selection” during the SFT process.</li>
</ol></li>
</ul>
<h2
id="introduce-some-agent-implementation-frameworks-what-are-the-differences-between-these-frameworks-what-scenarios-is-langgraph-suitable-for-what-are-the-ways-to-build-agents-with-langgraph">8.
Introduce Some Agent Implementation Frameworks; What are the Differences
Between These Frameworks; What Scenarios is LangGraph Suitable For; What
are the Ways to Build Agents with LangGraph</h2>
<ul>
<li><strong>Frameworks</strong>: AutoGPT (autonomous navigation), CrewAI
(multi-role collaboration), LangGraph (cyclic flow control).</li>
<li><strong>Advantages of LangGraph</strong>: Supports
<strong>Stateful</strong> and <strong>Cyclic</strong>. Traditional
LangChain is a DAG (Directed Acyclic Graph), which struggles to handle
complex logic that requires repeated iterations and corrections.</li>
<li><strong>Building Methods</strong>: 1. <strong>StateGraph</strong>
(explicit state definition); 2. <strong>Nodes &amp; Edges</strong>
(logical nodes and edges).</li>
</ul>
<h2
id="scenario-question-a-customer-inputs-a-screenshot-of-a-software-or-web-interface-how-to-help-users-understand-the-function-of-each-component-of-the-interface-through-rag-honestly-i-didnt-quite-understand-define-input-and-output-yourself-how-to-distinguish-similar-components-like-image-boxes-and-video-boxes">9.
Scenario Question: A Customer Inputs a Screenshot of a Software or Web
Interface, How to Help Users Understand the Function of Each Component
of the Interface Through RAG (??? Honestly, I didn’t quite understand),
Define Input and Output Yourself; How to Distinguish Similar Components
Like Image Boxes and Video Boxes</h2>
<h3 id="solution-definition">Solution Definition</h3>
<ul>
<li><strong>Input</strong>: Interface screenshot + target component
location (Bounding Box) or coordinates.</li>
<li><strong>Output</strong>: Function description and interaction logic
of the component.</li>
<li><strong>Implementation Process</strong>:
<ol type="1">
<li><strong>Preprocessing</strong>: Use a multimodal model (e.g., GPT-4o
or dedicated OCR + object detection model) to extract elements from the
screenshot.</li>
<li><strong>Indexing</strong>: Store the features of the components
(visual features + location information + associated text) in a vector
database.</li>
<li><strong>Retrieval</strong>: When the user clicks or inputs a
location, calculate the overlap of coordinates or feature
similarity.</li>
<li><strong>Generation</strong>: Generate descriptions by combining the
component’s documentation (Context).</li>
</ol></li>
</ul>
<h3
id="distinguishing-similar-components-image-box-vs-video-box">Distinguishing
Similar Components (Image Box vs Video Box)</h3>
<ol type="1">
<li><strong>Multimodal Features</strong>: Video boxes typically come
with play button features (triangle icon) and progress bar
features.</li>
<li><strong>Code/Metadata</strong>: If extracted from the code layer,
check the differences between <code>&lt;img&gt;</code> tags and
<code>&lt;video&gt;</code> or <code>&lt;iframe&gt;</code> tags.</li>
<li><strong>Temporal Analysis</strong>: If it is dynamic input, the
video box will have frame rate changes, while the image box remains
static.</li>
</ol>
<p><a
target="_blank" rel="noopener" href="https://www.xiaohongshu.com/explore/69188729000000000503bb66?app_platform=ios&amp;app_version=9.12.2&amp;share_from_user_hidden=true&amp;xsec_source=app_share&amp;type=normal&amp;xsec_token=CBO_gMH8TYsZlSZ4cVu3YNidnacfVrk2ZnNVz1MuchRRk=&amp;author_share=1&amp;xhsshare=WeixinSession&amp;shareRedId=ODxFMjU-Sk42NzUyOTgwNjdHOTo2Rj1K&amp;apptime=1765672895&amp;share_id=d1250146cbed4d6287b12a57fcc72633">Original
Link</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://xloverflow.github.io">Xiang Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://xloverflow.github.io/2025/12/14/Personal/%E6%B7%98%E5%A4%A9ai-agent%E9%9D%A2%E7%BB%8F/">https://xloverflow.github.io/2025/12/14/Personal/%E6%B7%98%E5%A4%A9ai-agent%E9%9D%A2%E7%BB%8F/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI-Agent/">AI Agent</a><a class="post-meta__tags" href="/tags/%E9%9D%A2%E7%BB%8F/">面经</a></div><div class="post-share"><div class="social-share" data-image="https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/12/14/CS336/CS336-Lec1-Tokenization/" title="CS336-Lec1 Tokenization"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">CS336-Lec1 Tokenization</div></div><div class="info-2"><div class="info-item-1">Lec1 mainly introduces the basic concepts of Tokenization and several common Tokenizer methods, including Character Tokenizer, Byte Tokenizer, Word Tokenizer, and BPE Tokenizer, analyzing their advantages, disadvantages, and applicable scenarios.</div></div></div></a><a class="pagination-related" href="/2025/10/03/Deep-Learning/CNN_P2/" title="CNNs - Part 2"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251002142654568.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">CNNs - Part 2</div></div><div class="info-2"><div class="info-item-1">Notes on Convolutional Neural Networks (CNN)</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2026/01/12/Personal/Deconstructing%20Agentic%20Coding%20with%20First%20Principles:%20From%20Theory%20to%20Practice/" title="Deconstructing Agentic Coding with First Principles: From Theory to Practice"><img class="cover" src="https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-12</div><div class="info-item-2">Deconstructing Agentic Coding with First Principles: From Theory to Practice</div></div><div class="info-2"><div class="info-item-1">This article is from a ByteDance expert, titled "Deconstructing Agentic Coding with First Principles: From Theory to Practice." I gained a lot from reading it.</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://pica.zhimg.com/80/v2-b6830c2136b7784c0aba649af7ec2867_1440w.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Xiang Li</div><div class="author-info-description">Xiang Li's Blog</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XLOverflow"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Talk is cheap. Show me the code.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#taotian-ai-agent-interview-experience"><span class="toc-number">1.</span> <span class="toc-text">TaoTian AI Agent
Interview Experience</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction-to-the-rag-process-understanding-encoding-models-principles-advantages-and-disadvantages-how-to-evaluate-encoding-model-capabilities"><span class="toc-number">1.1.</span> <span class="toc-text">1.
Introduction to the RAG Process; Understanding Encoding Models,
Principles, Advantages, and Disadvantages; How to Evaluate Encoding
Model Capabilities</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#principles-and-advantagesdisadvantages-of-encoding-models"><span class="toc-number">1.1.1.</span> <span class="toc-text">Principles
and Advantages&#x2F;Disadvantages of Encoding Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#evaluation-metrics"><span class="toc-number">1.1.2.</span> <span class="toc-text">Evaluation Metrics</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-are-the-classifications-of-rag-what-implementation-frameworks-exist-for-multimodal-rag-how-are-pseudo-multimodal-rag-and-multimodal-rag-implemented-and-what-are-the-differences-what-type-of-multimodal-rag-can-clip-be-used-for-and-why"><span class="toc-number">1.2.</span> <span class="toc-text">2.
What are the Classifications of RAG; What Implementation Frameworks
Exist for Multimodal RAG; How are Pseudo-Multimodal RAG and Multimodal
RAG Implemented, and What are the Differences; What Type of Multimodal
RAG Can CLIP Be Used For, and Why</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#naive-rag-simple-retrieval"><span class="toc-number">1.2.1.</span> <span class="toc-text">Naive RAG (Simple Retrieval)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#advanced-rag-preprocessing-postprocessing"><span class="toc-number">1.2.2.</span> <span class="toc-text">Advanced RAG
(Preprocessing + Postprocessing)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#modular-rag-modular-composition"><span class="toc-number">1.2.3.</span> <span class="toc-text">Modular RAG (Modular
Composition)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multimodal-rag-implementation"><span class="toc-number">1.2.4.</span> <span class="toc-text">Multimodal RAG
Implementation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#how-to-evaluate-rag-what-is-the-most-important-aspect-of-the-rag-evaluation-system"><span class="toc-number">1.3.</span> <span class="toc-text">3.
How to Evaluate RAG; What is the Most Important Aspect of the RAG
Evaluation System</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-are-the-pain-points-of-traditional-rag-introduce-graphrag-what-are-the-challenges-of-graphrag-how-does-graphrag-handle-incremental-scenarios"><span class="toc-number">1.4.</span> <span class="toc-text">4.
What are the Pain Points of Traditional RAG; Introduce GraphRAG, What
are the Challenges of GraphRAG; How Does GraphRAG Handle Incremental
Scenarios</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pain-points-of-traditional-rag"><span class="toc-number">1.4.1.</span> <span class="toc-text">Pain Points of Traditional
RAG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#graphrag"><span class="toc-number">1.4.2.</span> <span class="toc-text">GraphRAG</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduce-the-responsibilities-of-fine-tuning-what-is-the-most-important-aspect-of-fine-tuning-large-models"><span class="toc-number">1.5.</span> <span class="toc-text">5.
Introduce the Responsibilities of Fine-tuning; What is the Most
Important Aspect of Fine-tuning Large Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-are-the-methods-of-post-training-what-are-the-methods-of-fine-tuning-how-are-they-done-lora-principles-and-parameter-count"><span class="toc-number">1.6.</span> <span class="toc-text">6.
What are the Methods of Post-training; What are the Methods of
Fine-tuning, How are They Done; LoRA Principles and Parameter Count</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#post-training-methods"><span class="toc-number">1.6.1.</span> <span class="toc-text">Post-training Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fine-tuning-methods"><span class="toc-number">1.6.2.</span> <span class="toc-text">Fine-tuning Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lora-principles"><span class="toc-number">1.6.3.</span> <span class="toc-text">LoRA Principles</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduce-dpo-what-is-the-difference-between-dpo-and-ppo"><span class="toc-number">1.7.</span> <span class="toc-text">7.
Introduce DPO; What is the Difference Between DPO and PPO</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ppo-principles"><span class="toc-number">1.7.1.</span> <span class="toc-text">PPO Principles</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#why-is-ppo-training-unstable"><span class="toc-number">1.7.2.</span> <span class="toc-text">Why is PPO Training Unstable?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#core-essence-of-dpo-and-orpo"><span class="toc-number">1.7.3.</span> <span class="toc-text">Core Essence of DPO and ORPO</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduce-some-agent-implementation-frameworks-what-are-the-differences-between-these-frameworks-what-scenarios-is-langgraph-suitable-for-what-are-the-ways-to-build-agents-with-langgraph"><span class="toc-number">1.8.</span> <span class="toc-text">8.
Introduce Some Agent Implementation Frameworks; What are the Differences
Between These Frameworks; What Scenarios is LangGraph Suitable For; What
are the Ways to Build Agents with LangGraph</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scenario-question-a-customer-inputs-a-screenshot-of-a-software-or-web-interface-how-to-help-users-understand-the-function-of-each-component-of-the-interface-through-rag-honestly-i-didnt-quite-understand-define-input-and-output-yourself-how-to-distinguish-similar-components-like-image-boxes-and-video-boxes"><span class="toc-number">1.9.</span> <span class="toc-text">9.
Scenario Question: A Customer Inputs a Screenshot of a Software or Web
Interface, How to Help Users Understand the Function of Each Component
of the Interface Through RAG (??? Honestly, I didn’t quite understand),
Define Input and Output Yourself; How to Distinguish Similar Components
Like Image Boxes and Video Boxes</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#solution-definition"><span class="toc-number">1.9.1.</span> <span class="toc-text">Solution Definition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#distinguishing-similar-components-image-box-vs-video-box"><span class="toc-number">1.9.2.</span> <span class="toc-text">Distinguishing
Similar Components (Image Box vs Video Box)</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11711 Advanced NLP: Retrieval and RAG"/></a><div class="content"><a class="title" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG">11711 Advanced NLP: Retrieval and RAG</a><time datetime="2026-02-14T22:08:21.000Z" title="Created 2026-02-14 17:08:21">2026-02-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/13/15642-Machine-Learning-Systems/15642-ML-Systems-Distributed-Training-and-Parallelization/" title="15642 Machine Learning Systems: Distributed Training and Parallelization"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="15642 Machine Learning Systems: Distributed Training and Parallelization"/></a><div class="content"><a class="title" href="/2026/02/13/15642-Machine-Learning-Systems/15642-ML-Systems-Distributed-Training-and-Parallelization/" title="15642 Machine Learning Systems: Distributed Training and Parallelization">15642 Machine Learning Systems: Distributed Training and Parallelization</a><time datetime="2026-02-13T21:00:00.000Z" title="Created 2026-02-13 16:00:00">2026-02-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/13/11868-LLM-Sys/11868-LLM-Sys-Decoding/" title="11868 LLM Sys: Decoding"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11868 LLM Sys: Decoding"/></a><div class="content"><a class="title" href="/2026/02/13/11868-LLM-Sys/11868-LLM-Sys-Decoding/" title="11868 LLM Sys: Decoding">11868 LLM Sys: Decoding</a><time datetime="2026-02-13T01:00:00.000Z" title="Created 2026-02-12 20:00:00">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/12/11868-LLM-Sys/11868-LLM-Sys-Tokenization-and-Embedding/" title="11868 LLM Sys: Tokenization and Embedding"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11868 LLM Sys: Tokenization and Embedding"/></a><div class="content"><a class="title" href="/2026/02/12/11868-LLM-Sys/11868-LLM-Sys-Tokenization-and-Embedding/" title="11868 LLM Sys: Tokenization and Embedding">11868 LLM Sys: Tokenization and Embedding</a><time datetime="2026-02-12T20:30:00.000Z" title="Created 2026-02-12 15:30:00">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/15642-Machine-Learning-Systems/15642-ML-Systems-Transformer-Attention-Optimizations/" title="15642 Machine Learning Systems: Transformer, Attention, and Optimizations"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="15642 Machine Learning Systems: Transformer, Attention, and Optimizations"/></a><div class="content"><a class="title" href="/2026/02/09/15642-Machine-Learning-Systems/15642-ML-Systems-Transformer-Attention-Optimizations/" title="15642 Machine Learning Systems: Transformer, Attention, and Optimizations">15642 Machine Learning Systems: Transformer, Attention, and Optimizations</a><time datetime="2026-02-09T19:30:00.000Z" title="Created 2026-02-09 14:30:00">2026-02-09</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Xiang Li</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'fb37ffde539166b338d8',
      clientSecret: '00c01014243d312219aa68b6a2e22f7f19f4c8ef',
      repo: 'blog-comments',
      owner: 'XLOverflow',
      admin: ['XLOverflow'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || 'd855ab826a6a95cf7a70ec89575ae7e2'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>
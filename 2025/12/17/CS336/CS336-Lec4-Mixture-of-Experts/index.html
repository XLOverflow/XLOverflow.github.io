<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CS336-Lec4 Mixture of Experts | Life is not a race, but a journey</title><meta name="author" content="Xiang Li"><meta name="copyright" content="Xiang Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="This article summarizes the content of Lecture 4 of the CS336 course, focusing on the principles, implementation methods, and applications of the Mixture of Experts model within the Transformer archit">
<meta property="og:type" content="article">
<meta property="og:title" content="CS336-Lec4 Mixture of Experts">
<meta property="og:url" content="https://xloverflow.github.io/2025/12/17/CS336/CS336-Lec4-Mixture-of-Experts/index.html">
<meta property="og:site_name" content="Life is not a race, but a journey">
<meta property="og:description" content="This article summarizes the content of Lecture 4 of the CS336 course, focusing on the principles, implementation methods, and applications of the Mixture of Experts model within the Transformer archit">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png">
<meta property="article:published_time" content="2025-12-17T22:06:33.000Z">
<meta property="article:modified_time" content="2026-02-15T05:04:17.011Z">
<meta property="article:author" content="Xiang Li">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="CS336">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Mixture of Experts">
<meta property="article:tag" content="Stanford">
<meta property="article:tag" content="Study Notes">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CS336-Lec4 Mixture of Experts",
  "url": "https://xloverflow.github.io/2025/12/17/CS336/CS336-Lec4-Mixture-of-Experts/",
  "image": "https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png",
  "datePublished": "2025-12-17T22:06:33.000Z",
  "dateModified": "2026-02-15T05:04:17.011Z",
  "author": [
    {
      "@type": "Person",
      "name": "Xiang Li",
      "url": "https://xloverflow.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xloverflow.github.io/2025/12/17/CS336/CS336-Lec4-Mixture-of-Experts/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CS336-Lec4 Mixture of Experts',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://pica.zhimg.com/80/v2-b6830c2136b7784c0aba649af7ec2867_1440w.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/List/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/List/gallery/"><i class="fa-fw fa fa-image"></i><span> Album</span></a></li><li><a class="site-page child" href="/List/movies/"><i class="fa-fw fas fa-video"></i><span> Videos</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Life is not a race, but a journey</span></a><a class="nav-page-title" href="/"><span class="site-name">CS336-Lec4 Mixture of Experts</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/List/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/List/gallery/"><i class="fa-fw fa fa-image"></i><span> Album</span></a></li><li><a class="site-page child" href="/List/movies/"><i class="fa-fw fas fa-video"></i><span> Videos</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><!-- Language switch button styled like menu item--><div class="menus_items lang-switch"><div class="menus_item"><a class="site-page lang-toggle" href="/zh/"><i class="fas fa-language fa-fw"></i><span> 中文</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">CS336-Lec4 Mixture of Experts</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-17T22:06:33.000Z" title="Created 2025-12-17 17:06:33">2025-12-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-15T05:04:17.011Z" title="Updated 2026-02-15 00:04:17">2026-02-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Stanford-CS336/">Stanford CS336</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="cs336-lec4-mixture-of-experts">CS336-Lec4 Mixture of
Experts</h1>
<p>In the modern competition of ultra-large-scale LLMs, the Mixture of
Experts (MoE) model has become a core technology for achieving
“trillions of parameters” and “controllable computational costs.”</p>
<h2 id="core-definition-of-moe">Core Definition of MoE</h2>
<p>Traditional Transformer models are dense, where every Token activates
all parameters. The basic idea of MoE is to replace the massive FFN with
multiple parallel expert networks, and then add a routing layer to
determine which expert(s) a Token will enter.</p>
<p><img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218010555148.png" /></p>
<p>The output <span class="math inline">\(\mathbf{h}_t^l\)</span> of the
MoE layer at position <span class="math inline">\(t\)</span> can be
represented as the weighted sum of the outputs from the selected
experts: <span class="math display">\[
\mathbf{h}_t^l = \sum_{i=1}^{N} \left( g_{i,t} \cdot \text{FFN}_i
(\mathbf{u}_t^l) \right) + \mathbf{u}_t^l
\]</span> where:</p>
<ul>
<li><span class="math inline">\(N\)</span> is the total number of
experts.</li>
<li><span class="math inline">\(\mathbf{u}_t^l\)</span> is the input
Token vector for that layer.</li>
<li><span class="math inline">\(g_{i,t}\)</span> is the <strong>Gating
Weight</strong> computed by the router, typically calculated via
<strong>Top-K routing</strong>, as discussed in the next section.</li>
</ul>
<h2 id="routing-mechanism">Routing Mechanism</h2>
<p>The routing function is a very important part of MoE, as it
determines the efficiency of parameter utilization. We will first
introduce some possible implementations of routing mechanisms, which can
generally be categorized into those that require Learning and those that
do not:</p>
<ul>
<li>Learning-required mechanisms include Top-K and RL-based
routing.</li>
<li>Non-learning mechanisms include Hash and Base Routing.</li>
</ul>
<p>Here, we will briefly introduce the two non-learning mechanisms:</p>
<ul>
<li><strong>Hash Routing:</strong> Uses a fixed hash function to assign
Tokens to experts. Since the routing is fixed, there is no need to
<strong>learn</strong> the Router parameters, thus avoiding
non-differentiability issues.</li>
<li><strong>BASE Routing:</strong> Transforms the routing decision into
a <strong>Linear Assignment problem</strong> to find the optimal global
matching.</li>
</ul>
<p>However, most models currently use Choose Top-K, which also has
several variants.</p>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218011033467.png" style="zoom:40%;" /></p>
<h3
id="mathematical-details-of-top-k-routing-mainstream-approach">Mathematical
Details of Top-K Routing (Mainstream Approach)</h3>
<p>The router first calculates the relevance score <span
class="math inline">\(s_{i,t}\)</span> between the Token and the expert
embedding vector <span class="math inline">\(e_i\)</span>: <span
class="math display">\[
s_{i,t} = \text{Softmax}_i (\mathbf{u}_t^{lT} e_i^l)
\]</span> Then, it implements sparse activation through the Top-K
operator: <span class="math display">\[
g_{i,t} = \begin{cases} s_{i,t}, &amp; s_{i,t} \in \text{TopK}(\{s_{j,t}
| 1 \le j \le N\}, K) \\ 0, &amp; \text{otherwise} \end{cases}
\]</span>
<img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218011325691.png" alt="image-20251218011325691" style="zoom:60%;" /></p>
<h3 id="modern-architecture-variant-deepseekmoe">Modern Architecture
Variant: DeepSeekMoE</h3>
<p>DeepSeek introduces more refined designs to enhance the effectiveness
of MoE:</p>
<ul>
<li><strong>Fine-grained expert segmentation:</strong> Splits large
experts into multiple smaller experts (e.g., <span
class="math inline">\(2N\)</span>), allowing for more precise knowledge
combinations.</li>
<li><strong>Shared Expert Isolation:</strong> Sets fixed experts that
handle all Tokens sharing basic common knowledge, reducing redundancy
among routing experts.</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218011738375.png" /></p>
<h2 id="stability-of-training">Stability of Training</h2>
<p>The core challenge of MoE lies in how to train it stably. To improve
training efficiency, the model needs to exhibit sparsity, but the sparse
gating mechanism (Top-K) is <strong>Non-differentiable</strong>.
Additionally, we need to maintain load balancing among experts; without
constraints on the Router, traffic can concentrate on certain experts,
leading to others not being trained and becoming “dead experts.” We have
the following solutions to address this issue.</p>
<h3 id="reinforcement-learning">Reinforcement Learning</h3>
<p>The principle is straightforward: treat the entire Router as an agent
and the Tokens as actions, using reinforcement learning algorithms to
optimize the routing strategy based on the final loss (as a reward).</p>
<p>However, this method is <strong>not commonly used</strong>; while
logically correct, it suffers from <strong>high gradient variance and
computational complexity</strong>, making it less favorable in
large-scale training compared to other solutions.</p>
<h3 id="stochastic-perturbations">Stochastic Perturbations</h3>
<p>The principle is to add <strong>Gaussian noise</strong> or
<strong>Jitter</strong> to the routing logits, forcing the model to
explore some unconventional paths. <span class="math display">\[
H(x)_i = (x \cdot W_g)_i + \text{StandardNormal}() \cdot
\text{Softplus}((x \cdot W_{noise})_i)
\]</span> Even if the initial weights are poor, randomness allows each
expert to have a chance to be trained, making the routing more robust
and avoiding the emergence of dead experts.</p>
<h3 id="auxiliary-loss">Auxiliary Loss</h3>
<p>To ensure that each expert shares the task evenly, an auxiliary loss
is introduced, meaning that experts used more frequently receive greater
penalties, with the minimum loss ensuring that tasks are evenly
distributed among experts: <span class="math display">\[
\text{Loss}_{aux} = \alpha \cdot N \cdot \sum_{i=1}^N f_i \cdot P_i
\]</span> where:</p>
<ul>
<li><span class="math inline">\(f_i\)</span> (distribution ratio):
Represents the proportion of Tokens assigned to expert <span
class="math inline">\(i\)</span> in that batch.</li>
</ul>
<p><span class="math display">\[
f_{i} = \frac{1}{T} \sum_{x \in \mathcal{B}} \mathbb{I}\{argmax \ p(x) =
i\}
\]</span></p>
<ul>
<li><span class="math inline">\(P_i\)</span> (routing probability
ratio): Represents the total probability assigned to expert <span
class="math inline">\(i\)</span> by the Router.</li>
</ul>
<p><span class="math display">\[
P_{i} = \frac{1}{T} \sum_{x \in \mathcal{B}} p_{i}(x)
\]</span></p>
<h3 id="implementation-of-deepseek-variants">Implementation of DeepSeek
Variants</h3>
<p><strong>DeepSeek v1-2 (Dual Balance of Experts and Devices):</strong>
Introduces <code>Per-expert</code> Loss (consistent with Switch
Transformer) to ensure balance among experts, and
<code>Per-device</code> Loss to ensure balance in cross-GPU
communication (All-to-All).</p>
<p><strong>DeepSeek v3 (No Auxiliary Loss Balance):</strong> Introduces
the Per-expert Bias (<span class="math inline">\(b_i\)</span>)
mechanism: <span class="math display">\[
S_{i,t}^{\prime} = \begin{cases} s_{i,t}, &amp; s_{i,t}+b_{i} \in
Topk(\{s_{j,t}+b_{j} | 1 \le j \le N_{r}\}, K_{r}) \\ 0, &amp;
\text{otherwise} \end{cases}
\]</span> Adjusts the bias <span class="math inline">\(b_i\)</span>
through online learning to achieve balance without disrupting the
gradient of the main loss (Auxiliary-loss-free).</p>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218020026696.png" alt="image-20251218020026696" style="zoom: 33%;" /></p>
<h2
id="system-optimization-distributed-parallelism-and-computational-optimization">System
Optimization: Distributed Parallelism and Computational
Optimization</h2>
<p>Due to the enormous parameter scale, the physical implementation of
MoE heavily relies on parallelization.</p>
<h3 id="device-placement">1. Device Placement</h3>
<ul>
<li><strong>All-to-All Dispatch:</strong> Tokens are distributed across
devices to the corresponding expert nodes based on routing results.</li>
<li><strong>All-to-All Combine:</strong> Computation results are
returned while maintaining sequence order.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218020429348.png" alt="image-20251218020429348" style="zoom:70%;" /></p>
<h3 id="computational-operator-optimization-megablocks">2. Computational
Operator Optimization (MegaBlocks)</h3>
<p>Traditional matrix multiplication is inefficient when facing uneven
loads. Libraries like MegaBlocks introduce <strong>Block Sparse
MM</strong>, which can efficiently handle variable-length expert
computations, avoiding resource waste due to padding.</p>
<p><img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218020552365.png" /></p>
<h2 id="advanced-techniques">Advanced Techniques</h2>
<p><strong>z-loss (Numerical Smoothing):</strong> To prevent Softmax
from overflowing at low precision, it penalizes <span
class="math inline">\(\log^2 Z\)</span> (where <span
class="math inline">\(Z\)</span> is the partition function) to force
logits to remain within a safe range.</p>
<p><strong>Upcycling:</strong> Trained dense model FFN weights can be
cloned multiple times as initial values for MoE experts, significantly
shortening the training time from scratch, showing substantial
improvements on some models.</p>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218023241811.png" alt="image-20251218023241811" style="zoom:50%;" /></p>
<p><strong>MTP (Multi-Token Prediction):</strong> A technique used in
DeepSeek v3. It adds a lightweight module outside the main model to
predict multiple future Tokens at once, enhancing the model’s ability to
model long texts.</p>
<p><img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218023351698.png" /></p>
<p><strong>MLA (Multi-Head Latent Attention):</strong> A key solution in
DeepSeek v3 to the KV Cache bottleneck. It compresses Q, K, and V into a
low-dimensional “latent” space, requiring only a small latent vector
<span class="math inline">\(c_t^{KV}\)</span> to be cached during
inference, significantly reducing memory usage. Additionally, through a
decoupled design, some dimensions do not participate in compression (a
<strong>hard rule set during model architecture</strong>) to accommodate
rotary position encoding (RoPE), resolving conflicts between position
encoding and compressed cache.</p>
<ol type="1">
<li><strong>Why is caching avoided?</strong> A: The reconstruction
matrix <span class="math inline">\(W^{UK}\)</span> can be directly
<strong>absorbed into the projection of the query matrix Q. This means
that during inference, we </strong>only need to cache the
low-dimensional <span class="math inline">\(c_t^{KV}\)</span>** in
memory, rather than caching the reconstructed multi-head K and V.</li>
</ol>
<p><span class="math display">\[
\text{Score} = (h W_Q)^T \times (W_{UK} c_t^{KV}) = h \cdot (W_Q W_{UK})
\cdot c_t^{KV}
\]</span></p>
<ol start="2" type="1">
<li><strong>Why should RoPE be decoupled? Can’t we just add RoPE
directly in the latent space?</strong> A: No, looking directly at the
formula, we cannot merge the matrices into one, which would require us
to restore the Key, thus ruining the plan to save memory.</li>
</ol>
<p><span class="math display">\[
\text{Score} = (R_m h W_Q)^T \times (R_n W_{UK} c_n^{KV}) = h W_Q \cdot
(R_m^T R_n) \cdot W_{UK} c_n^{KV}
\]</span></p>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20251218023318356.png" alt="image-20251218023318356" style="zoom:30%;" /></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://xloverflow.github.io">Xiang Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://xloverflow.github.io/2025/12/17/CS336/CS336-Lec4-Mixture-of-Experts/">https://xloverflow.github.io/2025/12/17/CS336/CS336-Lec4-Mixture-of-Experts/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Study-Notes/">Study Notes</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/CS336/">CS336</a><a class="post-meta__tags" href="/tags/Stanford/">Stanford</a><a class="post-meta__tags" href="/tags/Mixture-of-Experts/">Mixture of Experts</a></div><div class="post-share"><div class="social-share" data-image="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2026/01/12/Personal/Deconstructing%20Agentic%20Coding%20with%20First%20Principles:%20From%20Theory%20to%20Practice/" title="Deconstructing Agentic Coding with First Principles: From Theory to Practice"><img class="cover" src="https://pica.zhimg.com/80/v2-24ea206b8da2b8b916c63fed288cd862_1440w.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Deconstructing Agentic Coding with First Principles: From Theory to Practice</div></div><div class="info-2"><div class="info-item-1">This article is from a ByteDance expert, titled "Deconstructing Agentic Coding with First Principles: From Theory to Practice." I gained a lot from reading it.</div></div></div></a><a class="pagination-related" href="/2025/12/16/CS336/CS336-Lec3-Architectures-Hyperparameters/" title="CS336-Lec3 Architectures &amp; Hyperparameters"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">CS336-Lec3 Architectures & Hyperparameters</div></div><div class="info-2"><div class="info-item-1">This article summarizes the content of the third lecture of the CS336 course, focusing on the evolution of Transformer architectures and their hyperparameter choices, including the latest developments in normalization methods, activation functions, position encoding, and more.</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2026/02/09/CS336/CS336-Assignment-1-Building-a-Transformer-Language-Model-from-Scratch/" title="CS336 Assignment 1: Building a Transformer Language Model from Scratch"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-08</div><div class="info-item-2">CS336 Assignment 1: Building a Transformer Language Model from Scratch</div></div><div class="info-2"><div class="info-item-1">A comprehensive reflection on implementing a complete Transformer language model pipeline from scratch — including BPE tokenizer with parallel pre-tokenization, decoder-only Transformer with RMSNorm/RoPE/SwiGLU, AdamW optimizer, and autoregressive text generation. Trained on TinyStories and OpenWebText with extensive experiments on learning rate sweeps, batch size studies, and architectural ablations.</div></div></div></a><a class="pagination-related" href="/2025/12/16/CS336/CS336-Lec3-Architectures-Hyperparameters/" title="CS336-Lec3 Architectures &amp; Hyperparameters"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-16</div><div class="info-item-2">CS336-Lec3 Architectures &amp; Hyperparameters</div></div><div class="info-2"><div class="info-item-1">This article summarizes the content of the third lecture of the CS336 course, focusing on the evolution of Transformer architectures and their hyperparameter choices, including the latest developments in normalization methods, activation functions, position encoding, and more.</div></div></div></a><a class="pagination-related" href="/2025/12/14/CS336/CS336-Lec1-Tokenization/" title="CS336-Lec1 Tokenization"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-14</div><div class="info-item-2">CS336-Lec1 Tokenization</div></div><div class="info-2"><div class="info-item-1">Lec1 mainly introduces the basic concepts of Tokenization and several common Tokenizer methods, including Character Tokenizer, Byte Tokenizer, Word Tokenizer, and BPE Tokenizer, analyzing their advantages, disadvantages, and applicable scenarios.</div></div></div></a><a class="pagination-related" href="/2025/12/15/CS336/CS336-Lec2-PyTorch-Resource-accounting/" title="CS336-Lec2 PyTorch &amp; Resource accounting"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20251214181527015.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-14</div><div class="info-item-2">CS336-Lec2 PyTorch &amp; Resource accounting</div></div><div class="info-2"><div class="info-item-1">This section focuses on the 'compute black box' behind model training. Starting from the microscopic details of floating-point formats, it delves into FLOPs calculation formulas, analyzes the characteristics of modern hardware, and finally provides a comprehensive optimization guide ranging from mathematical principles to PyTorch code implementation.</div></div></div></a><a class="pagination-related" href="/2026/01/29/11711-Advanced-NLP/11711-Advanced-NLP-Architectures/" title="11711 Advanced NLP: Architectures"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-29</div><div class="info-item-2">11711 Advanced NLP: Architectures</div></div><div class="info-2"><div class="info-item-1">Notes on RNN architectures, encoder-decoder models, and attention mechanisms from CMU 11-711 Advanced NLP.</div></div></div></a><a class="pagination-related" href="/2026/01/23/11711-Advanced-NLP/11711-Advanced-NLP-Fundamentals/" title="11711 Advanced NLP: Fundamentals"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-22</div><div class="info-item-2">11711 Advanced NLP: Fundamentals</div></div><div class="info-2"><div class="info-item-1">Notes and summaries for CMU 11-711 Advanced NLP.</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://pica.zhimg.com/80/v2-b6830c2136b7784c0aba649af7ec2867_1440w.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Xiang Li</div><div class="author-info-description">Xiang Li's Blog</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XLOverflow"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Talk is cheap. Show me the code.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cs336-lec4-mixture-of-experts"><span class="toc-number">1.</span> <span class="toc-text">CS336-Lec4 Mixture of
Experts</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#core-definition-of-moe"><span class="toc-number">1.1.</span> <span class="toc-text">Core Definition of MoE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#routing-mechanism"><span class="toc-number">1.2.</span> <span class="toc-text">Routing Mechanism</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#mathematical-details-of-top-k-routing-mainstream-approach"><span class="toc-number">1.2.1.</span> <span class="toc-text">Mathematical
Details of Top-K Routing (Mainstream Approach)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#modern-architecture-variant-deepseekmoe"><span class="toc-number">1.2.2.</span> <span class="toc-text">Modern Architecture
Variant: DeepSeekMoE</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stability-of-training"><span class="toc-number">1.3.</span> <span class="toc-text">Stability of Training</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#reinforcement-learning"><span class="toc-number">1.3.1.</span> <span class="toc-text">Reinforcement Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-perturbations"><span class="toc-number">1.3.2.</span> <span class="toc-text">Stochastic Perturbations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#auxiliary-loss"><span class="toc-number">1.3.3.</span> <span class="toc-text">Auxiliary Loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#implementation-of-deepseek-variants"><span class="toc-number">1.3.4.</span> <span class="toc-text">Implementation of DeepSeek
Variants</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#system-optimization-distributed-parallelism-and-computational-optimization"><span class="toc-number">1.4.</span> <span class="toc-text">System
Optimization: Distributed Parallelism and Computational
Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#device-placement"><span class="toc-number">1.4.1.</span> <span class="toc-text">1. Device Placement</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#computational-operator-optimization-megablocks"><span class="toc-number">1.4.2.</span> <span class="toc-text">2. Computational
Operator Optimization (MegaBlocks)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#advanced-techniques"><span class="toc-number">1.5.</span> <span class="toc-text">Advanced Techniques</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11711 Advanced NLP: Retrieval and RAG"/></a><div class="content"><a class="title" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG">11711 Advanced NLP: Retrieval and RAG</a><time datetime="2026-02-14T22:08:21.000Z" title="Created 2026-02-14 17:08:21">2026-02-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/13/15642-Machine-Learning-Systems/15642-ML-Systems-Distributed-Training-and-Parallelization/" title="15642 Machine Learning Systems: Distributed Training and Parallelization"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="15642 Machine Learning Systems: Distributed Training and Parallelization"/></a><div class="content"><a class="title" href="/2026/02/13/15642-Machine-Learning-Systems/15642-ML-Systems-Distributed-Training-and-Parallelization/" title="15642 Machine Learning Systems: Distributed Training and Parallelization">15642 Machine Learning Systems: Distributed Training and Parallelization</a><time datetime="2026-02-13T21:00:00.000Z" title="Created 2026-02-13 16:00:00">2026-02-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/13/11868-LLM-Sys/11868-LLM-Sys-Decoding/" title="11868 LLM Sys: Decoding"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11868 LLM Sys: Decoding"/></a><div class="content"><a class="title" href="/2026/02/13/11868-LLM-Sys/11868-LLM-Sys-Decoding/" title="11868 LLM Sys: Decoding">11868 LLM Sys: Decoding</a><time datetime="2026-02-13T01:00:00.000Z" title="Created 2026-02-12 20:00:00">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/12/11868-LLM-Sys/11868-LLM-Sys-Tokenization-and-Embedding/" title="11868 LLM Sys: Tokenization and Embedding"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11868 LLM Sys: Tokenization and Embedding"/></a><div class="content"><a class="title" href="/2026/02/12/11868-LLM-Sys/11868-LLM-Sys-Tokenization-and-Embedding/" title="11868 LLM Sys: Tokenization and Embedding">11868 LLM Sys: Tokenization and Embedding</a><time datetime="2026-02-12T20:30:00.000Z" title="Created 2026-02-12 15:30:00">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/15642-Machine-Learning-Systems/15642-ML-Systems-Transformer-Attention-Optimizations/" title="15642 Machine Learning Systems: Transformer, Attention, and Optimizations"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="15642 Machine Learning Systems: Transformer, Attention, and Optimizations"/></a><div class="content"><a class="title" href="/2026/02/09/15642-Machine-Learning-Systems/15642-ML-Systems-Transformer-Attention-Optimizations/" title="15642 Machine Learning Systems: Transformer, Attention, and Optimizations">15642 Machine Learning Systems: Transformer, Attention, and Optimizations</a><time datetime="2026-02-09T19:30:00.000Z" title="Created 2026-02-09 14:30:00">2026-02-09</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Xiang Li</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'fb37ffde539166b338d8',
      clientSecret: '00c01014243d312219aa68b6a2e22f7f19f4c8ef',
      repo: 'blog-comments',
      owner: 'XLOverflow',
      admin: ['XLOverflow'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || 'a63df16ccbf0dab3aa60594a4860f18a'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>
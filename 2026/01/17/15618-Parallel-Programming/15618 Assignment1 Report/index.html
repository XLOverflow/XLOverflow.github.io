<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>15618 Assignment 1 Report | Life is not a race, but a journey</title><meta name="author" content="Xiang Li"><meta name="copyright" content="Xiang Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Assignment 1 report for CMU 15-618, covering pthreads speedup analysis and SIMD vectorization.">
<meta property="og:type" content="article">
<meta property="og:title" content="15618 Assignment 1 Report">
<meta property="og:url" content="https://xloverflow.github.io/2026/01/17/15618-Parallel-Programming/15618%20Assignment1%20Report/index.html">
<meta property="og:site_name" content="Life is not a race, but a journey">
<meta property="og:description" content="Assignment 1 report for CMU 15-618, covering pthreads speedup analysis and SIMD vectorization.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png">
<meta property="article:published_time" content="2026-01-17T01:00:00.000Z">
<meta property="article:modified_time" content="2026-01-17T01:00:00.000Z">
<meta property="article:author" content="Xiang Li">
<meta property="article:tag" content="15618">
<meta property="article:tag" content="Assignment">
<meta property="article:tag" content="CMU">
<meta property="article:tag" content="Parallel Programming">
<meta property="article:tag" content="Pthreads">
<meta property="article:tag" content="SIMD">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "15618 Assignment 1 Report",
  "url": "https://xloverflow.github.io/2026/01/17/15618-Parallel-Programming/15618%20Assignment1%20Report/",
  "image": "https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png",
  "datePublished": "2026-01-17T01:00:00.000Z",
  "dateModified": "2026-01-17T01:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Xiang Li",
      "url": "https://xloverflow.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xloverflow.github.io/2026/01/17/15618-Parallel-Programming/15618%20Assignment1%20Report/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '15618 Assignment 1 Report',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://pica.zhimg.com/80/v2-b6830c2136b7784c0aba649af7ec2867_1440w.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/List/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/List/gallery/"><i class="fa-fw fa fa-image"></i><span> Album</span></a></li><li><a class="site-page child" href="/List/movies/"><i class="fa-fw fas fa-video"></i><span> Videos</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Life is not a race, but a journey</span></a><a class="nav-page-title" href="/"><span class="site-name">15618 Assignment 1 Report</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/List/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/List/gallery/"><i class="fa-fw fa fa-image"></i><span> Album</span></a></li><li><a class="site-page child" href="/List/movies/"><i class="fa-fw fas fa-video"></i><span> Videos</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><!-- Language switch button styled like menu item--><div class="menus_items lang-switch"><div class="menus_item"><a class="site-page lang-toggle" href="/zh/"><i class="fas fa-language fa-fw"></i><span> 中文</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">15618 Assignment 1 Report</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2026-01-17T01:00:00.000Z" title="Created 2026-01-16 20:00:00">2026-01-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-01-17T01:00:00.000Z" title="Updated 2026-01-16 20:00:00">2026-01-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CMU-15-618-Parallel-Programming/">CMU 15-618 Parallel Programming</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1
id="assignment-1-exploring-multi-core-and-simd-parallelism-report">15618
Assignment 1 Exploring Multi-Core and SIMD Parallelism Report</h1>
<h2 id="problem-1-parallel-fractal-generation-using-pthreads">Problem 1:
Parallel Fractal Generation Using Pthreads</h2>
<h3 id="speedup-graph">1.1 Speedup Graph</h3>
<p><strong>Implementation:</strong> Multi-threaded Mandelbrot generation
using horizontal striping (spatial decomposition). Each thread
<u>processes consecutive rows</u>. For cases where the number of rows
(900) is not evenly divisible by the number of threads, the first (900 %
T) threads are <u>assigned one additional row</u> to ensure all rows are
processed.</p>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20260116145929648.png" alt="image-20260116145929648" style="zoom: 25%;" /></p>
<blockquote>
<p>Note: 16 threads use the same 8 physical cores via
hyperthreading.</p>
</blockquote>
<p><strong><u>And speedup is not linear.</u></strong> With 8 cores, we
achieve only <strong>3.97× speedup</strong> (49.6% efficiency) instead
of the ideal 8×.</p>
<p><u><strong>Hypothesis: Load Imbalance</strong>:</u></p>
<p>The horizontal striping strategy creates severe load imbalance
because:</p>
<ul>
<li><strong>Top/bottom rows</strong>: Points far from Mandelbrot
boundary diverge quickly (~10-50 iterations)</li>
<li><strong>Middle rows</strong>: Points near the boundary require
maximum iterations (256)</li>
<li>Result: Threads assigned to middle rows work significantly
longer</li>
</ul>
<p>Since total time equals the slowest thread, unbalanced work
significantly reduces speedup.</p>
<blockquote>
<p>Key Obeservation:</p>
<p>The sharp drop in efficiency from 2 threads (98%) to 4 threads (60%)
confirms that load imbalance is the dominant performance bottleneck, not
hardware limitations.</p>
</blockquote>
<h3 id="per-thread-timing-measurements">1.2 Per-Thread Timing
Measurements</h3>
<p>To verify the load imbalance hypothesis from Section 1.1, I
instrumented the code by adding timing measurements at the beginning and
end of workerThreadStart() using CycleTimer::currentSeconds().</p>
<figure>
<img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20260116151418165.png"
alt="image-20260116151418165" />
<figcaption aria-hidden="true">image-20260116151418165</figcaption>
</figure>
<p><strong><u>Analysis: Load Imbalance Confirmed</u></strong></p>
<p>The timing visualization clearly shows <strong>severe load
imbalance</strong> across all configurations. The color gradient reveals
the problem: threads processing top and bottom rows (green bars) finish
quickly, while threads handling middle rows (red bars) take
significantly longer. This pattern directly corresponds to the
Mandelbrot set’s computational structure—boundary regions require
maximum iterations while outer regions diverge quickly.</p>
<p>For 4 threads, this imbalance means two threads sit idle for most of
the execution time while two others continue working, wasting half the
available CPU capacity. With 8 threads, the problem worsens: most
threads finish early and wait for the few threads stuck processing
expensive boundary rows. This uneven distribution explains why we
achieve only 3.97× speedup with 8 cores instead of the ideal 8×—the
execution time is bottlenecked by the slowest thread, not the average
workload.</p>
<h3 id="improve-speedup">1.3 Improve Speedup</h3>
<p><strong>Strategy: Interleaved Row Assignment</strong></p>
<p>Instead of horizontal striping (consecutive rows per thread), I
implemented interleaved assignment where thread <em>i</em> processes
rows <em>i</em>, <em>i+T</em>, <em>i+2T</em>, <em>i+3T</em>, …, where
<em>T</em> is the total number of threads.</p>
<p>This simple static assignment ensures each thread processes a mix of
computationally cheap rows (top/bottom of image) and expensive rows
(near Mandelbrot boundary), automatically balancing the workload without
any synchronization.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Threads</th>
<th style="text-align: left;">View 1 Speedup</th>
<th style="text-align: left;">View 2 Speedup</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: left;">3.84×</td>
<td style="text-align: left;">3.82×</td>
</tr>
<tr class="even">
<td style="text-align: left;">8</td>
<td style="text-align: left;"><strong>7.56×</strong></td>
<td style="text-align: left;"><strong>7.53×</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">16</td>
<td style="text-align: left;">7.61×</td>
<td style="text-align: left;">7.35×</td>
</tr>
</tbody>
</table>
<p><strong><u>Scaling Behavior Analysis:</u></strong></p>
<p><strong>4→8 threads (4→8 cores):</strong> Speedup nearly doubles,
demonstrating excellent scaling as each additional thread runs on a
dedicated physical core with full computational resources.</p>
<p><strong>8→16 threads (8 cores with hyperthreading):</strong>
Performance improvement is limited or even decreases (View 2). Since
both configurations share the same 8 physical cores, the 16 threads
compete for execution units and cache via hyperthreading. For
compute-intensive Mandelbrot workloads with minimal memory stalls,
hyperthreading provides little benefit.</p>
<h2
id="problem-2-vectorizing-code-using-simd-intrinsics"><strong>Problem 2:
Vectorizing Code Using SIMD Intrinsics</strong></h2>
<h3 id="clampedexpvector">2.1 clampedExpVector</h3>
<p>The implementation follows the exponentiation by squaring algorithm
and processes W elements in parallel per vector instruction.</p>
<p><strong>Key Implementation Details:</strong></p>
<ol type="1">
<li><strong>Loop Structure</strong>: Process array in chunks of
VECTOR_WIDTH, with each iteration handling one vector of elements</li>
<li><strong>Mask Management</strong>: Use maskActive to track which
lanes still have exponent &gt; 0, terminating the loop when all lanes
complete</li>
<li><strong>Boundary Handling</strong>: Dynamically create masks using
_cmu418_init_ones(count) to correctly handle cases where N is not a
multiple of W</li>
<li><strong>Result Clamping</strong>: Vectorized the clamping logic to
limit results exceeding 4.18</li>
</ol>
<p><strong>Correctness</strong>: Passed all test cases including
non-aligned array sizes (e.g., N=3, N=10, N=100)</p>
<h3 id="vector-width-sweep-experiments">2.2 Vector Width Sweep
Experiments</h3>
<p><strong>Experimental Setup</strong>: Ran ./vrun -s 10000 with
VECTOR_WIDTH ∈ {2, 4, 8, 16, 32}</p>
<figure>
<img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20260116181624182.png"
alt="image-20260116181624182" />
<figcaption aria-hidden="true">image-20260116181624182</figcaption>
</figure>
<ol type="1">
<li><p><strong>Vector Utilization Analysis</strong></p>
<p><strong>Observation</strong>: Vector utilization remains high
(88.51%-89.45%) across all vector widths, with <u>only 0.94%
degradation</u> as W increases from 2 to 32. This demonstrates <u>low
sensitivity to vector width</u>.</p>
<p>This is because the iteration counts are proportional to
log₂(exponent), meaning a 10× difference in exponents (e.g., 100 vs
1000) results in only ~3 additional iterations. Since vector
instructions must <u>wait for the slowest lane to complete</u>, each
vector’s iteration count is determined by the element with the maximum
iterations. This low variance <u>ensures elements within a vector finish
at similar times, minimizing idle lanes regardless of vector
width</u>.</p></li>
<li><p><strong>Number of Vector Instructions Analysis</strong></p>
<p><strong>Observation</strong>: Total vector instructions decrease from
286,614 (W=2) to 18,471 (W=32), <u>approximately halving with each
doubling of vector width</u>. The measured instruction counts closely
follow the theoretical O(N/W) curve (red dashed line), confirming
near-ideal scaling.</p>
<p>The total instruction count <u>is determined by how many times the
outer loop runs</u>. When vector width doubles (e.g., W=4 to W=8), each
vector instruction can process twice as many elements, so the outer loop
only needs to run half as many times. Since the work inside each loop
iteration stays the same, <u>doubling W directly halves the total
instructions</u>. This <strong>93.6% reduction</strong> from W=2 to W=32
demonstrates that vectorization delivers the expected linear
speedup.</p></li>
</ol>
<h3 id="arraysumvector">2.3 <strong>arraySumVector</strong></h3>
<p>Implemented a tree reduction algorithm achieving <strong>O(N/W +
log₂W)</strong> span complexity:</p>
<p><strong>Algorithm:</strong></p>
<ol type="1">
<li><strong>Phase 1 - Vector Accumulation (O(N/W))</strong>: Sum all
array elements into a single vector register using vector addition</li>
<li><strong>Phase 2 - Tree Reduction (O(log₂W))</strong>: Reduce W
elements within the vector to a single scalar using hadd and interleave
operations in log₂W rounds</li>
</ol>
<p><strong>Correctness</strong>: Passed all tests for W = 2, 4, 8,
16</p>
<h2 id="problem-3-parallel-fractal-generation-using-ispc">Problem 3:
Parallel Fractal Generation Using ISPC</h2>
<h3 id="part-1-ispc-simd-parallelization-analysis">3.1 Part 1: ISPC SIMD
Parallelization Analysis</h3>
<p><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/Figure_1.png" alt="Figure_1" style="zoom:70%;" /></p>
<h4 id="x-theoretical-maximum-speedup">8x theoretical maximum
speedup</h4>
<p>The ISPC compiler is configured to emit 8-way AVX2 SIMD instructions,
which can <u>process 8 floating-point values simultaneously</u>.
Therefore, the theoretical maximum speedup is <strong>8x</strong>
compared to the serial implementation.</p>
<h4 id="simd-divergence-stall">SIMD Divergence (Stall)</h4>
<p>The observed average speedup of <strong>4.48x</strong> is only 56% of
the theoretical 8x maximum because <u>different pixels require different
numbers of iterations</u> to determine if they’re in the Mandelbrot
set—when processing 8 pixels together in SIMD, some finish quickly while
others take much longer, forcing <u>all lanes to wait for the slowest
one</u>, which wastes computation on idle lanes.</p>
<h4 id="performance-variation-across-views">Performance Variation Across
Views</h4>
<p>Different views show speedups ranging from <strong>4.01x to
4.88x</strong> (View 6: 4.88x best, View 5: 4.01x worst). Views with
<u>complex fractal boundaries have neighboring pixels with very
different iteration counts</u>, causing more SIMD lanes to wait idle,
while views with <u>smoother regions have pixels that finish at similar
times</u>, reducing wasted computation.</p>
<h3 id="part-2-ispc-tasks">3.2 Part 2: ISPC Tasks</h3>
<h4 id="speedup-with-tasks">Speedup with –tasks</h4>
<table>
<colgroup>
<col style="width: 34%" />
<col style="width: 14%" />
<col style="width: 26%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Implementation</th>
<th style="text-align: left;">Time (ms)</th>
<th style="text-align: left;">Speedup vs Serial</th>
<th style="text-align: left;">Speedup vs ISPC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Serial</td>
<td style="text-align: left;">176.369</td>
<td style="text-align: left;">1.00x</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">ISPC (SIMD only)</td>
<td style="text-align: left;">37.019</td>
<td style="text-align: left;">4.76x</td>
<td style="text-align: left;">1.00x</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ISPC + Tasks (2 tasks)</td>
<td style="text-align: left;">18.721</td>
<td style="text-align: left;"><strong>9.42x</strong></td>
<td style="text-align: left;"><strong>1.98x</strong></td>
</tr>
</tbody>
</table>
<p>The 2x improvement from tasks makes sense because the current
implementation only creates 2 tasks, utilizing only 2 out of 8 cores.
Performance can be significantly improved by increasing the task
count.</p>
<h4 id="find-the-optimal-tasks-count">Find the optimal tasks count</h4>
<figure>
<img
src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/image-20260116231307425.png"
alt="image-20260116231307425" />
<figcaption aria-hidden="true">image-20260116231307425</figcaption>
</figure>
<p><u><strong>Optimal number of tasks is 16</strong></u></p>
<p>The system has <strong>8 physical cores with
hyper-threading</strong>, allowing <strong>16 hardware threads</strong>
to run simultaneously. Using 16 tasks achieves the best performance
(<strong>32.49× speedup</strong>) because:</p>
<ol type="1">
<li><strong>Matches hardware capacity</strong>: 16 tasks fully utilize
all 16 hardware threads, keeping all execution units busy.</li>
<li><strong>Better load balancing</strong>: The Mandelbrot computation
has uneven workload—fractal boundaries require many more iterations than
solid regions. With only 2 tasks, one task might get stuck on a heavy
region while the other finishes early. With 16 smaller tasks, work
distributes more evenly across cores.</li>
<li><strong>Diminishing returns beyond 16</strong>: Using 32 tasks
(32.86×) shows minimal improvement over 16 tasks because task scheduling
overhead increases while load balancing benefits plateau.</li>
</ol>
<h4 id="pthread-vs-ispc-tasks">Pthread vs ISPC Tasks</h4>
<p>Pthreads are OS-level threads with significant overhead. Launching
10,000 of them would likely crash or severely slow down a system due to
excessive memory consumption and context switching.</p>
<p>In contrast, ISPC tasks are lightweight logical units. The runtime
maps them onto a small, fixed thread pool (typically matching the CPU
core count). Launching 10,000 tasks is efficient because they are
scheduled via a task queue.</p>
<p><strong>The key difference</strong> is Pthreads are for
coarse-grained parallelism (fewer tasks, high overhead), while ISPC
tasks enable fine-grained data parallelism (many tasks, low overhead).
This makes ISPC ideal for SPMD-style operations like pixel-level
processing.</p>
<h2 id="problem-4-iterative-square-root"><strong>Problem 4: Iterative
Square Root</strong></h2>
<h3 id="speedup">4.1 Speedup</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Serial: 682.707 ms</span><br><span class="line">ISPC (no tasks): 145.532 ms</span><br><span class="line">ISPC (with tasks): 20.079 ms</span><br><span class="line"></span><br><span class="line">SIMD speedup: 4.69x</span><br><span class="line">Multi-core speedup: 7.25x (145.532/20.079)</span><br><span class="line">Total speedup: 34.00x</span><br></pre></td></tr></table></figure>
<h3 id="initgood">4.2 initGood</h3>
<p><strong>Implementation</strong>: Set all values to
<code>2.999f</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Serial: 1698.132 ms</span><br><span class="line">ISPC (no tasks): 297.302 ms</span><br><span class="line">ISPC (with tasks): 33.920 ms</span><br><span class="line"></span><br><span class="line">SIMD speedup: 5.71x</span><br><span class="line">Multi-core speedup: 8.76x (297.302/33.920)</span><br><span class="line">Total speedup: 50.06x</span><br></pre></td></tr></table></figure>
<p>This choice maximizes speedup by:</p>
<ul>
<li><p><strong>Perfect SIMD efficiency</strong>: All elements
<u>converge in identical iterations</u>, eliminating lane divergence.
Every SIMD lane performs the same amount of work and <u>finishes
simultaneously with no idle waiting.</u> SIMD speedup <u>improved from
4.69x (random) to 5.71x</u>.</p>
<p><strong>Maximum multi-core benefit with hyper-threading</strong>: The
uniform heavy workload enables exceptional multi-core scaling.
<u>Multi-core speedup reached 8.76x, exceeding the baseline 7.25x</u>.
This demonstrates the <u>hyper-threading effect</u> mentioned in the
assignment - when all threads execute identical heavy workloads,
hyper-threading can provide additional performance beyond the physical
core count.</p></li>
</ul>
<h3 id="initbad">4.3 initBad</h3>
<p><strong>Implementation</strong>: Alternate between
<code>2.999f</code> and <code>1.0f</code> every 8 elements</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Serial: 234.384 ms</span><br><span class="line">ISPC (no tasks): 297.430 ms</span><br><span class="line">ISPC (with tasks): 33.926 ms</span><br><span class="line"></span><br><span class="line">SIMD speedup: 0.79x</span><br><span class="line">Multi-core speedup: 8.77x (297.430/33.926)</span><br><span class="line">Total speedup: 6.91x</span><br></pre></td></tr></table></figure>
<p><strong>Choice of values</strong>: <code>2.999f</code> requires much
more iterations, while <code>1.0f</code> requires ~0 iterations
(matching the initial guess). This creates maximum iteration count
divergence within each SIMD gang.</p>
<p><strong>SIMD performance</strong>: This pattern creates <u>maximum
work divergence within each SIMD vector</u> (gang size = 8), with 1 slow
element and 7 fast elements per vector. SIMD operates in lockstep where
all lanes must wait for the slowest lane, <u>performance drops below
serial execution (0.79x)</u>.</p>
<p><strong>Multi-core performance</strong>: Multi-core speedup
<u>remains very high at 8.77x</u>, nearly identical to initGood (8.76x).
<u>The pattern repeats uniformly across the array</u> (every 8th element
is slow), ensuring <u>balanced workload distribution across threads</u>
despite severe SIMD inefficiency within individual vectors.</p>
<h2 id="problem-5-blas-saxpy"><strong>Problem 5: BLAS</strong>
saxpy</h2>
<h3 id="analysis-of-saxpys-performance">5.1 Analysis of saxpy’s
performance</h3>
<table>
<colgroup>
<col style="width: 19%" />
<col style="width: 14%" />
<col style="width: 23%" />
<col style="width: 29%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="header">
<th>Version</th>
<th>Time (ms)</th>
<th>Bandwidth (GB/s)</th>
<th>Performance (GFLOPS)</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Serial</td>
<td>11.356</td>
<td>26.243</td>
<td>1.761</td>
<td>1.00x</td>
</tr>
<tr class="even">
<td>Streaming</td>
<td>11.242</td>
<td>26.509</td>
<td>1.779</td>
<td>1.01x</td>
</tr>
<tr class="odd">
<td><strong>ISPC</strong></td>
<td><strong>11.315</strong></td>
<td><strong>26.339</strong></td>
<td><strong>1.768</strong></td>
<td><strong>1.00x</strong></td>
</tr>
<tr class="even">
<td><strong>Task ISPC</strong></td>
<td><strong>11.133</strong></td>
<td><strong>26.768</strong></td>
<td><strong>1.796</strong></td>
<td><strong>1.02x</strong></td>
</tr>
</tbody>
</table>
<p>The workload is <strong><u>memory bandwidth-bound</u></strong>. Saxpy
accesses large amounts of data but performs only 2 FLOPs. The processor
spends far more time waiting for memory than computing. Despite saxpy
being trivially parallelizable, <u>ISPC and multi-core execution provide
minimal ~1.00x speedup</u>. All implementations saturate at
approximately 26-27 GB/s, indicating we’ve <u>reached the memory
bandwidth limit</u>.</p>
<p><u><strong>The program cannot be substantially improved through
parallelism alone.</strong></u> Adding more cores or SIMD lanes doesn’t
help when serial execution already maximize the memory bandwidth.
Potential improvements require <u>reducing memory traffic</u> (e.g.,
using non-temporal stores for the result vector to avoid cache
pollution, reducing bandwidth from 4N to 3N floats) or <u>upgrading to
higher bandwidth memory hardware</u>.</p>
<h3 id="extra-credit-why-4n-instead-of-3n">5.2 Extra Credit: Why 4N
instead of 3N?</h3>
<p>I think it’s because the cache’s behavior. Modern CPUs use a
write-allocate cache policy, meaning write operations must firstly load
the target data into the cache before modifying it. This is required for
cache coherence and locality optimization. So the additional N floats is
<u>reading result cache lines</u>.</p>
<h3 id="extra-credit-what-else-factors-could-affect">5.3 Extra Credit:
What else factors could affect?</h3>
<p>The observed bandwidth of 26-27 GB/s represents typical efficiency
for DDR4 memory systems. The gap between observed and theoretical peak
is due to:</p>
<ul>
<li><strong>DRAM timing overhead</strong>: DDR4 requires mandatory
delays between operations (CAS latency, row precharge time, refresh
cycles) during which the memory bus is idle. These timing constraints
typically reduce effective bandwidth to 60-70% of theoretical peak.</li>
<li><strong>Memory controller efficiency</strong>: Bank conflicts,
channel arbitration, and command scheduling in the memory controller add
additional overhead.</li>
</ul>
<h3 id="extra-credit-non-temporal-store-optimization">5.4 Extra Credit:
Non-temporal Store Optimization</h3>
<p><strong>Implementation</strong>: Modified saxpyStreaming() using SSE
intrinsics with <code>_mm_stream_ps</code> to bypass cache.</p>
<table>
<colgroup>
<col style="width: 19%" />
<col style="width: 13%" />
<col style="width: 23%" />
<col style="width: 29%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="header">
<th>Version</th>
<th>Time (ms)</th>
<th>Bandwidth (GB/s)</th>
<th>Performance (GFLOPS)</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Serial</td>
<td>11.124</td>
<td>26.791</td>
<td>1.798</td>
<td>1.00x</td>
</tr>
<tr class="even">
<td><strong>Streaming</strong></td>
<td><strong>8.138</strong></td>
<td><strong>36.623</strong></td>
<td><strong>2.458</strong></td>
<td><strong>1.37x</strong></td>
</tr>
<tr class="odd">
<td>ISPC</td>
<td>11.201</td>
<td>26.608</td>
<td>1.786</td>
<td>0.99x</td>
</tr>
<tr class="even">
<td>Task ISPC</td>
<td>11.125</td>
<td>26.789</td>
<td>1.798</td>
<td>1.00x</td>
</tr>
</tbody>
</table>
<p>Non-temporal stores reduce memory traffic from 4N to 3N floats,
achieving 1.37x speedup and bandwidth improvement from 26.8 GB/s to 36.6
GB/s.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://xloverflow.github.io">Xiang Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://xloverflow.github.io/2026/01/17/15618-Parallel-Programming/15618%20Assignment1%20Report/">https://xloverflow.github.io/2026/01/17/15618-Parallel-Programming/15618%20Assignment1%20Report/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CMU/">CMU</a><a class="post-meta__tags" href="/tags/15618/">15618</a><a class="post-meta__tags" href="/tags/Parallel-Programming/">Parallel Programming</a><a class="post-meta__tags" href="/tags/Assignment/">Assignment</a><a class="post-meta__tags" href="/tags/SIMD/">SIMD</a><a class="post-meta__tags" href="/tags/Pthreads/">Pthreads</a></div><div class="post-share"><div class="social-share" data-image="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2026/01/23/11711-Advanced-NLP/11711-Advanced-NLP-Fundamentals/" title="11711 Advanced NLP: Fundamentals"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">11711 Advanced NLP: Fundamentals</div></div><div class="info-2"><div class="info-item-1">Notes and summaries for CMU 11-711 Advanced NLP.</div></div></div></a><a class="pagination-related" href="/2026/01/16/15645-Database-Systems/15645-Database-Systems-relational-model-and-SQL/" title="15645 Database systems: Relational Model and SQL"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210604434.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">15645 Database systems: Relational Model and SQL</div></div><div class="info-2"><div class="info-item-1">Notes and summaries for CMU 15-645 Database Systems.</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2026/01/16/15618-Parallel-Programming/15618-Parallel-Programming-Lecture-Notes/" title="15618 Parallel Programming Lecture (1-4) Notes"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-15</div><div class="info-item-2">15618 Parallel Programming Lecture (1-4) Notes</div></div><div class="info-2"><div class="info-item-1">Notes and summaries for CMU 15-618 Parallel Programming.</div></div></div></a><a class="pagination-related" href="/2026/01/29/11711-Advanced-NLP/11711-Advanced-NLP-Architectures/" title="11711 Advanced NLP: Architectures"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-29</div><div class="info-item-2">11711 Advanced NLP: Architectures</div></div><div class="info-2"><div class="info-item-1">Notes on RNN architectures, encoder-decoder models, and attention mechanisms from CMU 11-711 Advanced NLP.</div></div></div></a><a class="pagination-related" href="/2026/01/23/11711-Advanced-NLP/11711-Advanced-NLP-Fundamentals/" title="11711 Advanced NLP: Fundamentals"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-22</div><div class="info-item-2">11711 Advanced NLP: Fundamentals</div></div><div class="info-2"><div class="info-item-1">Notes and summaries for CMU 11-711 Advanced NLP.</div></div></div></a><a class="pagination-related" href="/2026/01/29/11711-Advanced-NLP/11711-Advanced-NLP-Learning-Inference/" title="11711 Advanced NLP: Learning &amp; Inference"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-29</div><div class="info-item-2">11711 Advanced NLP: Learning &amp; Inference</div></div><div class="info-2"><div class="info-item-1">Notes on learning algorithms and inference methods from CMU 11-711 Advanced NLP.</div></div></div></a><a class="pagination-related" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-14</div><div class="info-item-2">11711 Advanced NLP: Retrieval and RAG</div></div><div class="info-2"><div class="info-item-1">Notes on retrieval systems, retrievers, and retrieval-augmented generation (RAG) from CMU 11-711 Advanced NLP.</div></div></div></a><a class="pagination-related" href="/2026/01/26/11868-LLM-Sys/11868-LLM-SyS-GPU-Programming-Acceleration/" title="11868 LLM Sys: GPU Programming &amp; Acceleration"><img class="cover" src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-25</div><div class="info-item-2">11868 LLM Sys: GPU Programming &amp; Acceleration</div></div><div class="info-2"><div class="info-item-1">Notes and summaries for CMU 11-868 LLM Systems: GPU Programming & Acceleration.</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://pica.zhimg.com/80/v2-b6830c2136b7784c0aba649af7ec2867_1440w.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Xiang Li</div><div class="author-info-description">Xiang Li's Blog</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XLOverflow"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Talk is cheap. Show me the code.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#assignment-1-exploring-multi-core-and-simd-parallelism-report"><span class="toc-number">1.</span> <span class="toc-text">15618
Assignment 1 Exploring Multi-Core and SIMD Parallelism Report</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-1-parallel-fractal-generation-using-pthreads"><span class="toc-number">1.1.</span> <span class="toc-text">Problem 1:
Parallel Fractal Generation Using Pthreads</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#speedup-graph"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 Speedup Graph</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#per-thread-timing-measurements"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 Per-Thread Timing
Measurements</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#improve-speedup"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 Improve Speedup</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-2-vectorizing-code-using-simd-intrinsics"><span class="toc-number">1.2.</span> <span class="toc-text">Problem 2:
Vectorizing Code Using SIMD Intrinsics</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#clampedexpvector"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 clampedExpVector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vector-width-sweep-experiments"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 Vector Width Sweep
Experiments</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#arraysumvector"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 arraySumVector</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-3-parallel-fractal-generation-using-ispc"><span class="toc-number">1.3.</span> <span class="toc-text">Problem 3:
Parallel Fractal Generation Using ISPC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#part-1-ispc-simd-parallelization-analysis"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 Part 1: ISPC SIMD
Parallelization Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#x-theoretical-maximum-speedup"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">8x theoretical maximum
speedup</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#simd-divergence-stall"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">SIMD Divergence (Stall)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#performance-variation-across-views"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">Performance Variation Across
Views</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#part-2-ispc-tasks"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 Part 2: ISPC Tasks</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#speedup-with-tasks"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">Speedup with –tasks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#find-the-optimal-tasks-count"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">Find the optimal tasks count</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pthread-vs-ispc-tasks"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">Pthread vs ISPC Tasks</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-4-iterative-square-root"><span class="toc-number">1.4.</span> <span class="toc-text">Problem 4: Iterative
Square Root</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#speedup"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 Speedup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#initgood"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 initGood</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#initbad"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 initBad</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-5-blas-saxpy"><span class="toc-number">1.5.</span> <span class="toc-text">Problem 5: BLAS
saxpy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#analysis-of-saxpys-performance"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 Analysis of saxpy’s
performance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#extra-credit-why-4n-instead-of-3n"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 Extra Credit: Why 4N
instead of 3N?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#extra-credit-what-else-factors-could-affect"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 Extra Credit:
What else factors could affect?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#extra-credit-non-temporal-store-optimization"><span class="toc-number">1.5.4.</span> <span class="toc-text">5.4 Extra Credit:
Non-temporal Store Optimization</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11711 Advanced NLP: Retrieval and RAG"/></a><div class="content"><a class="title" href="/2026/02/14/11711-Advanced-NLP/11711-Advanced-NLP-Retrieval-RAG/" title="11711 Advanced NLP: Retrieval and RAG">11711 Advanced NLP: Retrieval and RAG</a><time datetime="2026-02-14T22:08:21.000Z" title="Created 2026-02-14 17:08:21">2026-02-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/13/15642-Machine-Learning-Systems/15642-ML-Systems-Distributed-Training-and-Parallelization/" title="15642 Machine Learning Systems: Distributed Training and Parallelization"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="15642 Machine Learning Systems: Distributed Training and Parallelization"/></a><div class="content"><a class="title" href="/2026/02/13/15642-Machine-Learning-Systems/15642-ML-Systems-Distributed-Training-and-Parallelization/" title="15642 Machine Learning Systems: Distributed Training and Parallelization">15642 Machine Learning Systems: Distributed Training and Parallelization</a><time datetime="2026-02-13T21:00:00.000Z" title="Created 2026-02-13 16:00:00">2026-02-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/13/11868-LLM-Sys/11868-LLM-Sys-Decoding/" title="11868 LLM Sys: Decoding"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11868 LLM Sys: Decoding"/></a><div class="content"><a class="title" href="/2026/02/13/11868-LLM-Sys/11868-LLM-Sys-Decoding/" title="11868 LLM Sys: Decoding">11868 LLM Sys: Decoding</a><time datetime="2026-02-13T01:00:00.000Z" title="Created 2026-02-12 20:00:00">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/12/11868-LLM-Sys/11868-LLM-Sys-Tokenization-and-Embedding/" title="11868 LLM Sys: Tokenization and Embedding"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260126152238836.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11868 LLM Sys: Tokenization and Embedding"/></a><div class="content"><a class="title" href="/2026/02/12/11868-LLM-Sys/11868-LLM-Sys-Tokenization-and-Embedding/" title="11868 LLM Sys: Tokenization and Embedding">11868 LLM Sys: Tokenization and Embedding</a><time datetime="2026-02-12T20:30:00.000Z" title="Created 2026-02-12 15:30:00">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/15642-Machine-Learning-Systems/15642-ML-Systems-Transformer-Attention-Optimizations/" title="15642 Machine Learning Systems: Transformer, Attention, and Optimizations"><img src="https://raw.githubusercontent.com/XLOverflow/blog-image/main/20260122210733236.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="15642 Machine Learning Systems: Transformer, Attention, and Optimizations"/></a><div class="content"><a class="title" href="/2026/02/09/15642-Machine-Learning-Systems/15642-ML-Systems-Transformer-Attention-Optimizations/" title="15642 Machine Learning Systems: Transformer, Attention, and Optimizations">15642 Machine Learning Systems: Transformer, Attention, and Optimizations</a><time datetime="2026-02-09T19:30:00.000Z" title="Created 2026-02-09 14:30:00">2026-02-09</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Xiang Li</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'fb37ffde539166b338d8',
      clientSecret: '00c01014243d312219aa68b6a2e22f7f19f4c8ef',
      repo: 'blog-comments',
      owner: 'XLOverflow',
      admin: ['XLOverflow'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || 'cad625baf66a0b7390df8d372ae7a070'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>